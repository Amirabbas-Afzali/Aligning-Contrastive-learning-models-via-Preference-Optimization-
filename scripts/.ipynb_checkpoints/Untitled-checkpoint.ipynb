{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5def99bd-7cf8-4ee6-945e-e40121aed454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start program!\n",
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA H100 80GB HBM3\n",
      "Random Seed:  0\n",
      "tokenized dataset\n",
      "Number of classes: 101\n",
      "Train dataset size: 53025\n",
      "Validation dataset size: 22725\n",
      "Test dataset size: 22725\n"
     ]
    }
   ],
   "source": [
    "print('Start program!')\n",
    "\n",
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n",
    "\n",
    "import sys\n",
    "sys.path.append(f'/home/ak-research-01/cli/Aligning-CLIP-via-Preference-optimization/')\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, PILToTensor\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from torch.optim import Optimizer\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.optim import AdamW\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor\n",
    "from torch.nn import DataParallel\n",
    "import copy\n",
    "from accelerate import Accelerator\n",
    "import scipy as sp\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "from src.Dataset import DatasetHandler\n",
    "from src.Loss import DPO_Loss, PPO_Loss, KTO_Loss\n",
    "from src.utils import Metrics \n",
    "from src.Models import *\n",
    "from config.config import Train_Config\n",
    "import gc \n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "###############################################  Device   ###############################################\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "ngpu = torch.cuda.device_count()\n",
    "\n",
    "###############################################  Optimization type   ###############################################\n",
    "manualSeed = 0\n",
    "set_seed(manualSeed)\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "\n",
    "save_model = True\n",
    "\n",
    "method = 'dpo'  # options: 'dpo', 'ppo', 'kto' or 'CE' \n",
    "Train_Dataset = 'food'   # 'food' or 'sun' \n",
    "###############################################  Dataset   ###############################################\n",
    "train_Config = Train_Config() \n",
    "\n",
    "if method == 'dpo':\n",
    "    config = train_Config.get_dpo_config()\n",
    "elif method == 'kto':\n",
    "    config = train_Config.get_kto_config()\n",
    "elif method == 'ppo':\n",
    "    config = train_Config.get_ppo_config()\n",
    "elif method == 'CE':\n",
    "    config = train_Config.get_ce_config()\n",
    "else:\n",
    "    raise Exception(\"Please choose a correct method type.\")\n",
    "\n",
    "\n",
    "size = 168\n",
    "preprocessor = Compose([\n",
    "    Resize(size=size, interpolation=Image.BICUBIC),\n",
    "    CenterCrop(size=(size, size)),\n",
    "    PILToTensor(),\n",
    "])\n",
    "\n",
    "# Define the object\n",
    "num_typographic = 10\n",
    "obj = type('obj', (object,), {'dataset': f'{Train_Dataset}', 'num_typographic': num_typographic})\n",
    "\n",
    "# Initialize the DatasetHandler\n",
    "handler = DatasetHandler(obj, preprocessor, data_split_ratio=0.7, batch_size=2, pretokenize=True) \n",
    "\n",
    "# # Create and save the dataset\n",
    "# handler.create_data(\"/home/ali.rasekh/ambo/final/datasets/typographic_image_classes_sun.p\")\n",
    "\n",
    "# Load typographic image classes\n",
    "handler.load_typographic_image_classes(f\"/home/ak-research-01/cli/Aligning-CLIP-via-Preference-optimization/datasets/typographic_image_classes_{Train_Dataset}.p\")\n",
    "\n",
    "# Prepare prompts (if needed)\n",
    "prompts = handler.prepare_prompts()\n",
    "\n",
    "# Split the data\n",
    "handler.split_data()\n",
    "\n",
    "if method == 'ppo':\n",
    "    handler.ppo_process(dataset_name=Train_Dataset)\n",
    "\n",
    "# Get DataLoaders\n",
    "org_train_dataloader = handler.get_train_dataloader()\n",
    "test_dataloader = handler.get_test_dataloader()\n",
    "val_dataloader = handler.get_val_dataloader()\n",
    "\n",
    "# Print to verify the setup\n",
    "print(f\"Number of classes: {handler.NUM_CLASSES}\")\n",
    "print(f\"Train dataset size: {len(handler.train_subset)}\")\n",
    "print(f\"Validation dataset size: {len(handler.val_subset)}\")\n",
    "print(f\"Test dataset size: {len(handler.test_subset)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e71ea49-4aa8-4bd3-8e10-226e37b3da5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                         | 0/104 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512 10 tensor([ 90,  89,  78,  49,  11,  96,  40,  40,  28, 100,   5,  71,  74,   7,\n",
      "         89,  52,  97,   2,  30, 100,  35,  44,  31,  86,  33,  73,   8,  68,\n",
      "         14,  52,  26,  73,   6,  20,  73,  47,  16,  57,  86,  14,  56,  21,\n",
      "         69,  56,  48,  93,  64,  10,  37,  64, 100,  13,  29,  47,  44,  74,\n",
      "         41,  44,  45,  61,  37,  35,  54,  75,  96,  20,  61,  75,  72,   1,\n",
      "         79,  84,  50,  56,  31,  98,  63,  21,  68,  61,  89,  32,  85,  37,\n",
      "         78,  16,  88,  47,  36,  68,  73,  70,  87,   7,  49,  98,  47,   2,\n",
      "         85,  98,   1,  87,  80,  62,   3,  49,  69,  92,  14,  59,  42,  31,\n",
      "         95,  71,  20,  80,   8,  74,   8,  92,  49,  79,  42,  29,  79,  74,\n",
      "         41,  20,  94,  43,  71,  60,  87,  80,  26,  64,  21,  95,   9,  86,\n",
      "         72,  21,  64,  75,  69,   4,  75,   7,  48,  72,  24,  12,  18,  15,\n",
      "         79,   1,  82,  25,  36,  18,  15,  13,  51,  20,  94,  52,  39,   6,\n",
      "         34, 100,   4,  98,  21,  48,  99,   3,  61,  72,  41,  53,  46,   1,\n",
      "         63,  76,  25,  14,   6,  54,   0,  76,  27,  97,  26,   5,  84,  88,\n",
      "          3,  73,  82,  16,   8,  29,  38,  34,  71,  62,  90,  44,  34,  77,\n",
      "         25,  51,  49,  19,  88,  11,  50,  70,   6,  85,  15,  88,  29,   4,\n",
      "         21,  76,   7,  17,  32,  54,  80,  20,  12,  19,  45,  14,  26,  30,\n",
      "         38,  46,  99,  93,  85,  91,   3,  73,  31,  98,  39,  99,  21,  30,\n",
      "          1,  95,  31,  87,  42,   1,  13,   2,  76,  29,  54,  24,  57,  41,\n",
      "          4,  60,  91,  26,  13,   5,  48,   8,  98,  91,  65,  20,  46,  77,\n",
      "         57,  74,  42,  56,  17,  42,  86,  43,   8,  90,  32,  95,  12,  27,\n",
      "         50,  10,  84,  44,  41,  80,  49,  51,  96,  75,   2,  27,  27,  70,\n",
      "         92,  68,   2,  60,  15,  81,  48,  15,  15,  38,  83,  44,  30,  85,\n",
      "          7,  89, 100,  12,  24,  84,  24,  52,  10,  53,  78,  62,  93,  88,\n",
      "         52,  12,  36,  68,  76,  11,  63,  46,  81,  10,  48,  13,   8,  76,\n",
      "         37,   7,   4,  21,  57,  79,  90,   0,  20,  65,  80,   8,   5,   2,\n",
      "         44,   3,   3,  19,   1,  87,  46,  50,  39,  34,  24,  66,  11,  61,\n",
      "          4,  67,   3,   2,  73,  87,  32,   1,  38,  58,  37,  27,  10,  95,\n",
      "         44,  15,   3,  51,   5,  51,  98,  47,  89,  98,  77,  73,  77,  56,\n",
      "         28,  21,  88,  76,  71,  75,  62,  98,  92,   3,  75,  82,  21,  96,\n",
      "         55,  20,  32,  12,  90,  51,  27,  19,  65,  38,  35,  83,  49,  39,\n",
      "         55,  10,  87,  77,  54,  90,  30,  80,  46,  79,  45,  52,  67,  62,\n",
      "         27,  41,  73,  57,  68,  35,  18,  59,  77,  44,  36,   5,  28,  49,\n",
      "         32,  68,  56,  34,  12,   7,  37,  54,  95,  81,  57,  92,   6,  30,\n",
      "         11,  58,  64,  51,  29,   8,  53,  17,  86,  54,   7,   8,  99,  54,\n",
      "         58,  85,  61,   3,  94,  25,  62,  79,  51,  57,  37,  56,  93,  60,\n",
      "         20,  92,  43,  95,  42,  90,  22,  98]) \n",
      "\n",
      "\n",
      "\n",
      " [tensor([ 74,  25,  12,  25,  17,  39,  23,   3,  25,   0,  81,  33,  63,  63,\n",
      "         20,  80,   9,  27,  83,  90,  37,  34,  96,  56,  69,  59,  72,  89,\n",
      "         78,  37,  27,  31,  24,  15,   6,  12,   0,  13,  17,  16,  72,  31,\n",
      "          3, 100,  63,  15,   3,  70,  42,  59,  62,  57,  48,   7,  79,  97,\n",
      "         71,  62,  47,  57,  71,  52,  69,  77,  84,  15,  29,  58,  60,  69,\n",
      "         29,  58,  80,  34,  20,  64,  40,  80,  90,  24,  85,  37,  82,  67,\n",
      "         31,  17,  70,  23,  75,  60,  36,   9,  68,  21,   5,  18,  56,  89,\n",
      "         18,  93,   4,   7,  96,  93,   9,  27,  11,  99, 100,  72,  56,  82,\n",
      "         56,  66,  63,  17,   2,  69,  42,   8,  59,   1,  67,  57,  17,   7,\n",
      "         20,  47,  82,  47,   3,   9,  28,   1,  31,  22,  34,  22,  26,  81,\n",
      "         84,  70,  30,  74,  25,  83,  71,  37,  33,  16,  61,  25,  59,   2,\n",
      "          6,  32,  38,  83,  82,  61,  69,  20,  31,  12,  41,  80, 100,  72,\n",
      "         54,  90,  37,  21,  89,  95,  50,  14,  33,  42,  75,  86,  34,  90,\n",
      "          1,   3,  66, 100,  90,  78,  69,  17,  93,   8,  99,  62,  96,   3,\n",
      "         59,   5,  45,  11,  36,  30,  67,  12,  89,  95,  83,  26,  43,  66,\n",
      "         39,  67,  71,  65,  40,  16,  97,  63,  78,  10,  42,  41,  33,  66,\n",
      "         54,  56,  11,  47,  14,  26,  90,  77,  32,  91,   7,  10,  88,  16,\n",
      "         87,   1,  12,  92,  90,  35,  99,  30,  40,  69,  55,  25,   9,  68,\n",
      "         63,  49,  44,  71,  38,  31,  88,  74,  65,  30,  76,  92,  53,   1,\n",
      "         45,  37,  17,  91,  74,  44,  23,  92,   0,  20,  55,  33,  35,  65,\n",
      "         43,  75,  52,  89,  59,  21,  63,  16,  13,  25,  35,  84,  69,  14,\n",
      "         68,  28,  97,  18,  96,  56,  78,   8,   4,  15,  29,  79,  23,  73,\n",
      "          1,  87,  79,  43,  63,  44,  31,   2,  74,  52,  81,  36,  37,  17,\n",
      "         35,  55,  75,  66,  82,   2,  56,  33,  63,  79,  43,  29,  45,   7,\n",
      "         91,  70,  62,  60,  77,  22,  67,   3,  34,  18,  51,  80,  16,  83,\n",
      "         84,  95,   7,  92,  32,  85,  44,   5,  58,  73,  86,  16,  36,  57,\n",
      "         65,  12,  49,  79,  60,  92,  15,  26,  57,  59,  31,  57,  19,  94,\n",
      "         23,  48,  75,  42,  91,  79,  99,  46,  88,  91,   0,  50,  42,  91,\n",
      "         92,  30,   1,  24,  75, 100,  32,  19,  95,  15,  13,  52,  63,  62,\n",
      "         98,  15,  70,  41,   1,  83,  15,   6,  61,  18,  86,  70,  57,  92,\n",
      "         15,  76,  94,  76,  51,  37,  92,  88,  95,   0,  70,  16,  80,  43,\n",
      "         15,  39,   3,  44,  65,  37,   2,  11,  43,  93,  15,  77,  60,  23,\n",
      "         55,  51,  19,  61,   5,  77,  82,  71,  28,  98,  62,  13,  60,  82,\n",
      "          3,  38,  91,  91,  44,  39,  82, 100,  49,  31,  41,  40,   0,  69,\n",
      "         19,  70,  79,  90,  56,  49,  19,  37,  94,  26,  93,  22,  17,  82,\n",
      "         11,  84,   2,  26,  11,  11,  43,  74,  58,   0,  47,  90,  21,   4,\n",
      "         57,  78,  86,  98,  75,  59,  15,  72]), tensor([ 13,   1,  69,  32,  10,  11,   2,  45,  25,  87,  38,  86,  18,  72,\n",
      "         65,  10,  21,  66,  81,  26, 100,  10,   6,   4,  92,  65,  23,  91,\n",
      "         46,   3,  76,  58,  51,  90,  41,  79,  85,  68,  14,  58,  89,  19,\n",
      "         18,  37,   9,  60,  48,  92,  85,  57,  32,  87,  85,   8,   7,  40,\n",
      "         44,  51,  20,  57,  85,  67,  35,  77,  36,  80,   4,  17,  80,  35,\n",
      "         73,  12,  44,  55,  34,  97,  36,  46,  54,   1,  79,  92,  80,   7,\n",
      "         60,  10,  77,  42,  97,  90,  12,  22,  16,  28,  25,  68,  83,  18,\n",
      "         49,  90,  72,  27,  22,   9,  18,  26,  64,  88,   1,  71,  77,  33,\n",
      "         42,  16,  85,  17,  32,  35,  87,  31,  13,  51,   5,  84,  60,  42,\n",
      "         63,  69,  23,  21,  51,  64,  74,  86,   7,   1,  13,  73,   8,  19,\n",
      "         12,  19,  96,  48,  91,  33,   4,  71,  65,   8,  73,  74,  89,  40,\n",
      "         66,  83,  49,  45,  62,  57,  36,  51,  84,  49,  16,  49,   0,  30,\n",
      "          6,  21,  61,   0,   2,  61,  86,  43,  44,  89,  32,  20,  40,  89,\n",
      "          9,  65,  32,  70,  84,  87,   4,  70,  69,  88,  82,   9,  80,  72,\n",
      "         90,  42,  26,  37,  16,  47,  70,  78,  19,  29,  72,  43,  98,  79,\n",
      "         46,  17,  34,  63,  90,  71,  59,   8,  21,  91,  19,  72,  75,  89,\n",
      "          4,  83,  25,  58,  40,  51,  22,  29,  18,   0,  11,  71,  87,  79,\n",
      "         64,  12,  29,  61,  14,  43,  37,   3,   0,   8,  28,  72,  18,  99,\n",
      "         32,  32,  61,   3,  32,  13,  32,  49,  92,  65,  71,  21,  44,  22,\n",
      "         39,  97,  10,  59,  36,   0,  37,  19,  46,  55,  24,   7,  51,  84,\n",
      "         69,  53,  97,  32,  76,  89,  33,  79,  80,  21,  48,  74,  23,  73,\n",
      "         52,  14,  16,  43,  67,  71,  35,  46,  44,   3,  79,  81,  41,  66,\n",
      "         99,  70,  41,  46,  67,  33,  70,  22,  30,  62,  30,   5,  14,  11,\n",
      "          8,  95,  42,  81,  53,  95,  52,  71,  56,  31,  35,   0,  25,  22,\n",
      "         50,  70,  33,  94,  42,  32,  40,   7,  61,  68,   4,  55,  56,   4,\n",
      "          5,  58,  86,  96,  93,   5,  66,  80,  52,  12,  20,  63,  35,  51,\n",
      "         94,  25,  15,  49,  55,  43,  57,  71,  72,  61,  39,   9,  57,  88,\n",
      "         29,  35,  13,   7,  26,  17,  81,  41,  82,  60,  24,  48,  70,  19,\n",
      "         69,  65,  14,  83,  55,  85,  73,   5,  72,  94,  85,  14,  36,  54,\n",
      "         64,  17,  89,  45,  34,  79,   4,  31,  83,  31,  94,  41,  63,  70,\n",
      "         95,   2,   0,  23,  89,  43,  63,  12,  25,  44,  42,  80,  35,  37,\n",
      "         60,  42,  43,  47,  16,  49,   6,  32,  68,  92,  62,  84,  21,  96,\n",
      "         60,  84,  71,  63,  98,  81,  82,  75,   8,  50,  47,   4,  12,  48,\n",
      "         35,  12,   2,  68,  83,  35,  74,  89,  31,  17,  94,  64,  72,  58,\n",
      "         81,  11,  83,  59,  63,  43,  85,  55,  38,  93,  83,  97,  24,  23,\n",
      "         34,  75,  19,  75,  76,  69,  20,   8,  65,  69,  83,   7,  91,  35,\n",
      "         52,  70,  74,  30,  15,  59,  33,  91]), tensor([ 71,  12,  58,  99,   7,  17,   4,  61,  88,  67,  75,  98,  50,  54,\n",
      "         56,  68,  35,   9,  84,  63,  39, 100,   1,  39,  43,  23,  53,  18,\n",
      "         65,  91,   5,   6,  16,  99,  63,  28,  34,  42,  27,  76,  99,  32,\n",
      "          8, 100,  27,   6,  34,  73,  45,  29,   2,  75,  54,   6,  26,  98,\n",
      "         30,  71,  69,  91,  22,  86,  22,  35,  98,   6,   0,  97,   3,  75,\n",
      "         17,  68,  69,  36,  10,  31,  33,  94,  27,  25,  78,  70,  61,  40,\n",
      "         41,   4,  35,  25,  62,  86,  84,  25,  33,  15,  36,  12,  45,  60,\n",
      "         11,  56,  50,  85,  26,  38,  80,  42,  78,  35,  97,  70,  38,  27,\n",
      "         63,  86,  85,  65,  37,  87,  74,  82,  33,  42,  89,  53,  48,  16,\n",
      "         50,  35,  91,  23,  99,  51,  95,  45,  70,  73,  82,  13,  76,   7,\n",
      "         29,   7,  95,  84,  89,  28,   7,   3,  41,  18,  75,  70,  73,  81,\n",
      "         82,  10,  44,  39,  79,  81,  24,  40,  97,  28,  79,   9,  94,  21,\n",
      "         63,  69,  32,  11,  35,   3,  11,  30,  10,  57,   4,  17,  66,  34,\n",
      "         19,  45,  27,   6,  20,  19,  10,  20,  76,  67,  95,  23,  32,  82,\n",
      "         31,  91,  33,  99, 100,  48,   5,   2,  36,   2,  72,  56, 100,  91,\n",
      "         74,  66,  56,  52,  41,  37,  62,  37,  91,  42,  19,  70,  33,  25,\n",
      "         35,  14,  76,  35,  55,  63,  86,  96,  44,  49,  13,   6,  16,  67,\n",
      "         70,   7,  53,  94,  74,  44,  95,  97,   0,   8,   5,  72,   1,  62,\n",
      "         96,  46,  64,  78,  85,  82,  67, 100,  86,  39,  78,  38,  78,  66,\n",
      "         68,  31,  37,  71,  19,  75,  54,  52,  10,   0,  10,  25,  95,  42,\n",
      "         41,  22,  36,  97,  30,  72,  63,  85,   2,  63,  97,   9,  43,  64,\n",
      "         46,  74,  10,  49,   3,  31,  17,  71,  53,   1,   7,  86,  47,  90,\n",
      "         63,  73,  94,  59,  50,  71,  73,   6,  46,  57,  15,  34,  40,  88,\n",
      "         38,  88,  70,  51,  16,  96,  97,  89,   8,  28,  47,  65,  39,  85,\n",
      "         63,  88,  82,  28,  80,  95,  29,  96,  30,  22,  19,  90,  77,  32,\n",
      "         62,  54,  57,  67,  31,  57,  89,  89,  32,  33,  27,  65,  94,  74,\n",
      "         22,  39,  85,  40,  87,  22,   2,  68,  28,  17,  68,  59,  74,  37,\n",
      "         73, 100,  78,  32,   9,  98,  54,  48,  46,  65,  13,  59,  86,  27,\n",
      "         14,   6,  97,  34,  84,  48,  74,  90,  92,  49,  13,  64,  91,  12,\n",
      "         54,  60,  79,  51,  31,  57,  52,  37,   4,  88,  60, 100,  94,  70,\n",
      "         12,   4,  79,   5,   7,  10,  94,  28,  42,  50,  34,   1,  75,  95,\n",
      "         40,  36,   0,  23,  46,   8,  34,   9,  79,  82,  30,  18,  26,  79,\n",
      "         40,  34,  56,   1,  75, 100,   5,   4,  88,  62,  77,  68,  75,  53,\n",
      "         23,   5,  21,  43,  88,  53,  57,  53,  32,  72,  56,  18,  85,   9,\n",
      "          7,  37,  38,  55,  92,  37,   6,  92,  75,  55,  81, 100,  84,  52,\n",
      "          9,  78,  98,   5,  76,  21,  19,  49,  26,  87,  56,  60,  31,  90,\n",
      "         98,  76,  55,  33,  73,  87,  84,  12]), tensor([ 45,  41,  34,  58,  85,  82,   3,  86,  75,  13,  32,  52,  47,  65,\n",
      "          1,  63,   5,  24,  21,  89,  32,  68,  13,  92,  99,   9,  25,  23,\n",
      "         95,  79,  32,  28,  96,  97,  87,  95,  88,  65,  94,  63,  16,  53,\n",
      "         18,  45,  90,  24,  63, 100,  95,  19,  79,  80,  49,  74,  80,  23,\n",
      "         22,  16,  35,  94,  46,  80,  12,  32,   3,  77,  29,  20,  13,  10,\n",
      "         44,  47,  90,  87,  76,   6,  21,  10,  84,   0, 100,  12,   5,  59,\n",
      "         88,  25,  68,  60,  15,  13,  17,  88,  26,  20,  74,  77,   1,  66,\n",
      "         97,  55,  33,  73,  65,  40,  96,  94,  17,  91,  63,  45,  24,   3,\n",
      "         94,  89,  65,  17,  48,  30,  86,  98,  88,  16,  67,  80,  25,  75,\n",
      "         44,  72,  80,  77,  75,  33,  70,  60,  63,  36,  68,   9,  95,   1,\n",
      "         12,  11,  38,  12,  89,  18,  33,  38,  37,  40,  85,  97,  40,  23,\n",
      "         84,  88,  23,   9,  16,  99,  50,   6,  35,  66,  17,  23,  83,  19,\n",
      "         68,  98,  19,  73,  52,  50,  38,  47,  40,   1,  42,  28,  61,  54,\n",
      "         60,  58,  63,  28,  13,  35,  54,  74,  26,  67,  49,  71,  71,  20,\n",
      "         89,   0,  35,  78,  80,  35,  77,  65,  93,  96,  21,  35,  87,  56,\n",
      "         74, 100,   3,  91,  76,   0,  39,  17,   0,  28,  59,  66,  76,  65,\n",
      "         89,  16,  66,  37,  58,  92,  81,  31,  84,  44,  55,  43,  34,  83,\n",
      "         25,  86,  23,  65,  73,  82,  63,  94,  35,  16,  44,  33,  44,  38,\n",
      "         35,  38,  81,  44,  32,  51,  47,  69,  46,  49,  36,  33,  86,  47,\n",
      "         86,  28,  43,  31,  77,  49,  15,  13,   7,  79,  30,  41,  60,  68,\n",
      "         32,  13,  91,  49,  22,  84,  54,  10,  21,  17,  86,  34,  55,  80,\n",
      "         85,  95,  46,  95,  74,  96,  14,  99,  73,  19,   0,   6,  64,   6,\n",
      "          3,  35,  26,  70,  44,  10,  26,  21,  32,  52,  84,  99,  93,  77,\n",
      "         21,  44,  77,  46,  55,  56,  10,   4,  16,  31,  55,  38,  58,  76,\n",
      "          9,  98,   0,  29,  68,  28,  56,  42,  83,  43,   6,  77,  76,  99,\n",
      "         88,  19,  50,  28,  16,  60,  65,  82,  87,  43,  54,   5,  88,  60,\n",
      "         72,   6,  87,  83,  28,  33,   8,  63,  15,  23,  61,  70,  17,  52,\n",
      "         28,  17,  52,  98,  90,  92,  28,  25,  59,  41,  51,  32,  85,  57,\n",
      "         68,  94,  33,  89,  77,  95,  44,  32,  69,  71,   4,  94,  83,  25,\n",
      "         19,  84,  13,  27,  40,   0,  52,  99,  26,  76,  25,   2,   7,  36,\n",
      "         21,  35,  37,  81,  66,  20,  32,   1,  58,  94,  30,  10,  83,  86,\n",
      "         37,   2,  25,  88,  64,  86,  48,  97,  17,  73,  73,  44,  19,  75,\n",
      "         86,  57,  46,  49,  41,  40,   8,   8,  10,  28,  96,  99,  80,  15,\n",
      "         38,  74,  85,  23,   2,  19,   0,  94,  14,  85,  43,  55,  96,  40,\n",
      "          0,   9,  73,  73,  67,  55,  98,  86,  50,  94,  36,  93,  83,  55,\n",
      "         66,  37,  22,  18,  56,  87,  96,  73,  86,  87,  51,  85,  21,  96,\n",
      "         13,  71,  84,  28,  59,   6,  56,  63]), tensor([ 86,  68,  22,  89,  42,  43,  26,  31,  23,  84,  39,  96,  73,  19,\n",
      "        100,  17,  58,  35,  24,  25,  52,  23,  32,   3,  60,  22,   4,  69,\n",
      "         86,  11,  48,  36,  62,  99,  84,  91,  69,  20,   3,  61,  33,  70,\n",
      "         81,  14,  38,   0,   8,  28,   2,  97,  47,  72,  91,  90,  36,  38,\n",
      "         40,  19,  63,  12,  75,  84,  69,  30,  17,  55,  66,  63,  43,  35,\n",
      "         64,  14,  33,  74,  24,  44,  50,  99,  81,  57,  60,  95,  75, 100,\n",
      "         89,  13,  41,  11,   0,  44,  45,  88,  84,  40,  17,  68,  29,  19,\n",
      "         36,  30,  82,  14,  60,  20,  63,  40,  18,  80,  88,  94,  57,  18,\n",
      "         72,  98,  86,  76,  69,  21,  67,  68,  74,  70,   8,  78,  42,  79,\n",
      "         87,  23,  15, 100,  56,   7,  69,  60,  18,  50,  56,  76,  40,  83,\n",
      "         36,  74,  89,  30,  82,   7,   2,  68,  27,  85,  36,  11,  32,  28,\n",
      "         19,  54,  73,  18,  58,  41,  43,  32,  49,  63,  89,   8,  61,  32,\n",
      "         85,  31,  69,   7,  20,  83,  70,  92,  30,   6,  44,  68,  87,  12,\n",
      "          0,  49,  90,  16,  28,  95,  23,  95,  49,   3,   5,  18,  72,  86,\n",
      "         85,  46,  83,  90,  76,  28,  28,  52,  14,  48,   5,   9,  22,  63,\n",
      "         31,  30,  97,  22,  54,  20,   3,  96,  84,  77,  70,  63,  69,  66,\n",
      "         37,  12,  41,  77,  67,  51,  21,  89,  57,  77,  79,  70,   5,  94,\n",
      "         54,  51,  83,  19,  76,  55,  84,  78,  16,  64,  49,  47,  96,  28,\n",
      "         45,  87,  85,  46,  65,  79,  55,  56,  69,   7,  41,   0,  29,  78,\n",
      "         64,  38,  62,  83,  83,  74,  63,  34,  30,  52,  29,  33,  24,  70,\n",
      "         62,  18,  61,  83,  31,  59,  74,   5,  88,  87,  43,  82,  38,  97,\n",
      "         81,  41,  19,  27,  17,  19,  50,  79,  97,  44,  53,  81,  48,  27,\n",
      "         72,   0,  66,  55,  94,  37,  10,  34,   1,  49,  66,  77,  34,  82,\n",
      "         37,  58,  55,  78,  52,  53,  34,  11,   6,  70,  44,  91,   0,   4,\n",
      "         98,  93,  89,  82,  65,  71,   4,  60,  41,   2,  45,  61,  20,  59,\n",
      "         89,  85,   5,  66,  26,  92,  92,  27,  27,  84,  41,  91,  39,  95,\n",
      "         77,   2,  29,  39,  27,  62,  51,  37,  31,  37,  29,  46,  75,  44,\n",
      "         27,  52,  12,  78,  25,  22,  21,  25,  67,  99,  28,  80,  60,  61,\n",
      "         58,  33,  74,  58,  19, 100,  92,  41,  82,  89,   2,  29,  12,  80,\n",
      "         84,  55,  41,  22,   1,   5,  72,  12,  31,  76,  42,  96,   8,  91,\n",
      "          2,  83,  75,  50,  93,  89,  58,  24,  16,  50,  15,  36,  39,  73,\n",
      "          7,  70,  68,  31,  39,  59,  96,  51,  49,  56,  22,  22,  34,  58,\n",
      "         24,  59,  27,   4,  74,  66,  30,  36,  13,   7,  61,  71,  81,  80,\n",
      "         78,  64,  77,  16,  34,  74,  67,  35,   2,  85,  44,  83,  75,  40,\n",
      "         78,  63,  61,  59,  83,  30,  56,  18,  28,  57,  62,  96,  16,  90,\n",
      "         71,  17,  92,  62,  23,  12,  23,  73,  27,  49,  59,  83,  32,  73,\n",
      "         50,  43,  77,  44,   5,  45,  82,  35]), tensor([ 63,  27,  49,  61,  99,  17,  26,  61,  76,  78,  17,  78,  14,  19,\n",
      "          1,  27,  95,  44,   0,  53,  80,  68,  88,  34,  95,  71,  97,  26,\n",
      "         52,  12, 100,  23,  11,  34,  37,  79,  27,  12,  97,   8,  11,  69,\n",
      "         21,  23,  46,  68,  52,  31,  65,  96,  43,  60,  41,  77,  84,  76,\n",
      "         28,  12,  51,  30,  64,  30,  25,  49,  94,  95,  93,  21,  32,  50,\n",
      "         68,  92,   4,  91, 100,  87,  48,  35,  95,  17,  94,  77,  94,  88,\n",
      "         32,  96,  53,  57,  81,  74,  80,  29,  34,  76,  27,  52,   5,  64,\n",
      "         51,  35,  20,  53,  48,  23,  91,  23,  31,  27,   5,  91,  53,  46,\n",
      "          5,  53,  43,  83,  47,  80,   4,  67,  80,  61,  89,  71,   0,  69,\n",
      "          1,  38,  20,  66,  75,  83,  66,  44,  99,  42,  66,  84,  73,  80,\n",
      "         87,  17,  86,  99,  13,  95,  51,  65,  57,  17,  62,  74,  11,  75,\n",
      "         71,  80,  86,  68,  52,  42,   8,  88, 100,  52,   8,  20, 100,  63,\n",
      "         84,  11,  48,  11,  85,  80,  62,  82,  56,   5,  42,  59,  54,  79,\n",
      "         65,   5,  19,  27,  57,  84,  23,  51,  49,  78,  51,  63,  28,  49,\n",
      "         34,  49,  87,  57,   6,  45,  70,  95,  50,  35,  51,  95,  21,  29,\n",
      "         93,  19,  28,  51,  98,  45,  66,   0,  21,  67,  81,  65,  66,  93,\n",
      "         95,  24,  11,   7,  60,  81,   8,  92,  98,  43,  90,  59,  39,  18,\n",
      "         68,  24,  39,  83,  67,  57,  32,  55,  98,   0,  94, 100,  28,  86,\n",
      "         65,  91,  56,  29,  77,  77,   5,  34,  40,  19,  58,  77,  39,   7,\n",
      "         30,  52,  80,  10,   9,  15,   2,  74,  61,  13,  79,  82,  45,  60,\n",
      "         64,   1,  95,  31,  61,   1,  11,  57,  77,  19,  91,  23,  64,  91,\n",
      "         24,  60,   6,  37,  78,  65,  45,  86,  28,  46,  51,  56,  20,  99,\n",
      "         77,  86,  89,  44,  87,  87,  30,  84,  78,  30,  69,  60,  47,  88,\n",
      "         52,  74,  50,  55,  42,  30,  37, 100, 100,  55,  71,  49,  73,  48,\n",
      "         77,  73,  94,  45,  21,  67,  40,  81,  56,  42,  63,  27,  73,  64,\n",
      "          6,  14,  38,  92,  56,   6,  32,  14,  34,   3,  59,  73,  90,  49,\n",
      "         14,  53,  89,  14,  24,  85,  57,   6,  34,  50,  12,  56,  58,  25,\n",
      "         47,  45, 100,   3,  87,  67,   0,  40,  89,  52,  81,  67,  83,  65,\n",
      "         71,  70,  79,  13,  43,   0,  49,  42,  86,  58,  37,  17,  17,  94,\n",
      "         19,  77,  43,  27,  29,  27,  37,  99,  11,  54,  91,  88,  63,  70,\n",
      "          3,  40,  98,  73,   2,  98,  46,  24,  21,  33,  31,  71,  99,  91,\n",
      "         61,  42,  21,  23,   8,  56,  82,  89,  72,  98,  65,  79,  66,   9,\n",
      "         89,  56,  47,  66,  22,   3,  16,  46,  44,  85,  40,  89,  62,  91,\n",
      "         33,   0,  88,  64,   6,  97,  92,  10,  83,  38,  42,  10,  49,  45,\n",
      "         92,  61,  65,  86,  78,  98,  30,  91,  58,  24,  73,  94,   8,  21,\n",
      "          8,  14,  11,  72,  54,  15,  91,   1,  60,  98,  94,   0,  14,  10,\n",
      "         70,  22,  30,  35,  66,  42,  67,  69]), tensor([ 67,  50,   5,   1,  71,  64,  64,  59,  55,  48,  13, 100,  63,  23,\n",
      "         54,  39,   1,  29,  80,  44,   7,  73,  89,  25,  12,  53,  27,  91,\n",
      "         21,  88,  52,   8,  26,  77,  48,   1,  18,  21,  57,  87,  65,  10,\n",
      "         55,  97,  33,  46,  40,  28,  17,  10,  66,  59,  98,   7,  83,  29,\n",
      "         93,  77,  64,  70,  32,  82,  68,  43,  45,  55,  68,  32,  85,  65,\n",
      "         20,  27,  63,  10,  72,  30,  34,  32,  24,   9,  65,  56,  44,  35,\n",
      "         19,   6,  83,   6,  82,  19,  94,  66,  88,  73,  75,  13,  90,  61,\n",
      "         21,  66,  87, 100,  18,  68,   7,  82,  61,  36,  40,  93,  75,  23,\n",
      "         41,  82,  71,  12,  52,  38,  68,  63,  44,  78,  56,  65,  50,  55,\n",
      "         63,   1,  28,   5,  69,  38,  60,   3,  35,  10,   1,  24,  42,  65,\n",
      "         81,  86,   5,  86,  39,   7,  50,  83,  86,  88,  19,  50,  51,  44,\n",
      "         96,  54,  67,  12,  77,  27,  94,  49,  99,  54, 100,  44,  65,  27,\n",
      "         10,  14,  13,  88,  16,  32,  18,  50,  56,   9,  25,  60,  74,  82,\n",
      "         98,  16,  94,  76,  36,  12,   4,  34,   7, 100,   3, 100,  82,  11,\n",
      "         71,  86,  57,   8,  13,  21,  73,  85,  23,  95,  28,  93,  74,  79,\n",
      "         74,  85,  66,  42,  13,  30,  30,  82,  89,  14,  60,  21,  65,  54,\n",
      "         89,  55,  30,   2,  29,  15,  32,  70,  14,  28,  78,  56,  30,  14,\n",
      "         90,  92,  38,  79,  14,  66,  73,  30,  89,  51,  88,  15,  55,  13,\n",
      "         29,  55,  33,  54,  27,  53,  66,  29,  67,  38,   8,  96,  37,  64,\n",
      "         85,   1,  80,  74,  76,  77,  76,  60,  43,  52,  38,  46,  14,  13,\n",
      "         11,  79,  51,  70,  55,  81,  93,  41,  24,  58,  59,  43,  29,   2,\n",
      "         90,  20,  13,  31,  15,  14,   9,  31,  31,  18,  89,  31,  36,  59,\n",
      "          3,  13,  40,  38,   1,  84,  37,  28,  47,  97,  27,  46,  87, 100,\n",
      "         54,  30,  14,  33,  99,  68,  45,  83,  13,  94,  29,  95,  34,  69,\n",
      "         41,  17,  99,  62,  95,  14,  38,   7,  88,   0,  21,  12,  71,   9,\n",
      "         91,  78,  71,  40,  37,  70,  12,  46,  99,  66,  68,  95,   9,   3,\n",
      "         57,  91,  46,   9,  16,   8,  70,  95,  93,  49,  15,  60,  85,  22,\n",
      "         63,  27,  49,  55,   6,  18,  37,  53,  93,  62,  45,  57,  93,  68,\n",
      "         78,  84,  20,  15,  58,  62,   5,  32,  99,  75,  35,  88,  95,  53,\n",
      "         36,  80,  58,  78,  72,  34,  73,  18,  71,  62,  49,  38,  82,  39,\n",
      "         15,  18,  73,  91,  68,  60,  39,  18,  42,  75,  62,  24,  80,  30,\n",
      "         21,  85,  10,  50,  10,  56,  69,  42,  34,  71,  66,   7,  98,  32,\n",
      "         66,  22,  19,   7,  96, 100,  43,  86,  49,  75,  97,  31,  80,  93,\n",
      "         90,   9,  62,  76,  10,  33,  30,  52,  83,  33,   6,  38,  65,  42,\n",
      "         79,  62,  55,  46,  69,  75,  55,  71,  41,  22,  49,  61,  29,  59,\n",
      "         73,  56,  69,  82,  84,  79,  75,   9,   1,  91,  59,  24,  32,  66,\n",
      "         53,  84,  35,   8,  23,  58,  97,   5]), tensor([ 30,  13,  69,   5,  72,  37,  69,  31,  97,  32,   0,  62,  94,  83,\n",
      "         28,  27,  98,  86,  81,  69,   5,  64,  48,  21,  46,  35,  88,   6,\n",
      "         69,  33,  72,  62,  51,  69,  11,  70,   2,   1,  40,   7,  88,  30,\n",
      "         94,  34,  77,  46,  44,  91,  36,  61,  69,  15,  42,  61,  98,  39,\n",
      "         44,  33,  15,   6,  90,  12,  25,  85,  46,  98,  18,   6,  10,  17,\n",
      "         26,  94,  23, 100,  65,  28,  40,  11,  87,  75,  99,   3,  27,  29,\n",
      "         28,  77,  98,  46,  75,   8,  35,   7,   7,  99,  40,  16,  93,  72,\n",
      "         68,  45,   9,  93,  44,  13,   0,  35,  60,  52,   7,  36,  27,  14,\n",
      "         66,   0,  63,  24,  53,   0,  66,   1,  31,  24,  25,   5,  89,  41,\n",
      "         15,  26,  83,  14,  75,  28,  17,  66,  95,  58,  93,  59,  31,   1,\n",
      "         64,  24,  42,  20,  32,  94,  54,  23,  49,  76,  42,  59,  66,  79,\n",
      "         77,  14,  67,  52,  67,  41,  89,  63,  78,  89,  50,  31,  99,  87,\n",
      "         23,  61,   7,   4,  20,  93,  13,  27,   6,  30,  81,   6,  49,  17,\n",
      "         29,  56,  59,  26,  21,  47,  32,  64,  53,  36,   9,  64,  66,  83,\n",
      "         35,  99,  39,  36,  15,  16,  47,  41,  45,  33,  32,  48,  29,  78,\n",
      "         59,  38,  70,  31,  84,  39,  84,  93,  70,   2,  67,  55,  28,  21,\n",
      "         32,  28,  76,   6,  50,   7,  42,   0,  23,  61,  33,  43,  40,  88,\n",
      "         19,  19,  25,  96,  46,  88,  61,  94,  17,  53,  94,  35,  60,   3,\n",
      "          4,  89,  40,  53,  67,  97,  35,  69,  31,  99,  72,  76,  73,  87,\n",
      "         56,  96,  50,  11,  94,  99,  36,  79,  51,  62,  34,  75,  93,  47,\n",
      "         55,  17,  86,  46,  84,  79,  56,  34,  78,  27,  17, 100,  23,  99,\n",
      "         21,  18,  30,  91,   0,  99,  63,  29,  50,  32,  85,  76,  18,  24,\n",
      "         95,  67,  37,  53,   1,  93,  75,  45,   0,  30,  98,  50,  43,  77,\n",
      "         78,  37,  81,  35,  94,  82, 100,  83,  45,  20,  17,   7,  35,  92,\n",
      "          5,  72,  54,  72,  54,  95,  61,  63,  39,  31,  71,  63,  20,  58,\n",
      "         72,  39,  76,  72,  79,  20,  12,  57,  69,  21,  83,  48,  88,  60,\n",
      "         93,   9,  97,   6,  33,  73,  20,   7,  32,  23,  50,  77,  34,  79,\n",
      "         22,  70,  79,  41,  95,  25,  82,  48,  70,   2,  64,  44,   9,  34,\n",
      "        100,  17,  33,  64,  85,  73,   0,  34,  57,  82,  21,  32,  39,  71,\n",
      "          2,  93,  72,  41,  98,  28,  32,  77,  49,  14,  93,  77,  26,  76,\n",
      "         11,  55,  27,  47,  30,  48,  96,  68,   1,  49,  92,  73,  77,  98,\n",
      "         53,  72,  72,  50,  86,  54,  31,  17,   1,  29,  24,  35,  75,  65,\n",
      "         90,  90,  13,   2, 100,  79,  16,  63,  26,   0,  44,  44,  77,  40,\n",
      "          3,  70,  52,   4,  58,   8,   5,  74,  23,  10,  76,  91,  23,  98,\n",
      "          2,  84,  88,  27,  12,  55,  47,  65,  20,  59,  56,  15,  93,  31,\n",
      "         37,  82,  81,   0,  23,  19, 100,  17,  28,  38,  14,  65,   3,  43,\n",
      "         75,  81,  45,  26,  95,  56,  89,  43]), tensor([ 60,  57,  99,  73,  83,  39,  38,  90,  63,   3,  39,  44,  96,  59,\n",
      "         25,  21,  58,  13,  23,  11,  91,   3,  79,  26,  92,  11,  70,  35,\n",
      "         98,  61,  68,   3,  89,   7,  72,   8,  36,  21,  49,  38,  79,  83,\n",
      "         39,  79,  11,  43,  59,  42,  43,  43,  21,  98,  37,  93,  78,  17,\n",
      "         70,  49,   5,  32,  99,  53,   6,  87,  16,  44,  39,   7,  67,  16,\n",
      "         14,  67,  92,  58,  17,   4,  36,  12,  91,  87,   5,  41,  20,   3,\n",
      "         88,  71,  10,  73,  96,  14,  23,  38,  56,  39,  60,  47,  33,  51,\n",
      "         44,  79,  79,  38,  37,  40,  63,  22,  53,  85,  47,  98,  47,  89,\n",
      "         71,   9,  83,  65,   4,   8,  96,  56,  83,  62,  31,  98,  16,   1,\n",
      "          4,   0,  38,  20,  65,   6,  89,  85,  74,  96,  60,  88,  97,  10,\n",
      "         16,  34,  51,  51,  68,  19,   6,  59,  29,  46,  96,  55,  61,   9,\n",
      "         60,  19,  29,  85,  75,   6,  62,  28,  82,  33,  71,  16,  37,  38,\n",
      "         23,  33,  95,  74,   7,  17,  73,  97,   0,  26,  42,  36,  90,  24,\n",
      "         94,  28,  93,  62,  30,  39,  16,  21,   7,  85,   1,  70,  40,  29,\n",
      "         38,  54,  15,  53,  25,  67,  34,  57,  69,  85,  15,  30,  38,  63,\n",
      "         35,  18,  80,  61,  24,  32,  94,  24,  14,  14,  42,  56,  82,  71,\n",
      "         34,  18,  53,  11,  21,  42,  28,  66,  75,  37,  87,  70,  99,  31,\n",
      "         86,  44,  12,  80,  30,  89,  83,  37,  64,  55,  50,  26,  48,  14,\n",
      "         66,  36,  53,   9,  28,  40,  79,  22,  15,   9,  87,  46,  99,  78,\n",
      "         96,  23,  82,  21,  75,  45,  14,   7,  46,  65,  75,  97,  90,  43,\n",
      "         35,  16,   5,  97,  28,  89,  21,  94,  71,  31,  43,  67,  61,  83,\n",
      "          1,  94,  64,  60,  58,  96,   8,  44,  30,  91,  17,   1,  78,   5,\n",
      "          5,  54,  37, 100,  95,  28,  26,   2,  81,  33,  14,  29,  85,  97,\n",
      "         34,  75,  19,   6,  86,  69,  56,  31,  21,  84,  57,  27,  68,  70,\n",
      "         49,  53,  30,  21,   9,   9,  25,  92,  37,  47,  33,  47,  54,  30,\n",
      "         47,  14,   8,  62,  55,  53,   8,  55,  14,  40,  26,  69,  94,  36,\n",
      "         12,  24,  10,  77,  12,  23,  34,  19,  73,  18,  78,  92,  74,  92,\n",
      "         14,  71,  20,  35,  59,  35,  24,  64,  53,  44,   3,  59,  25,  10,\n",
      "         86,  44,   1,   3,  93,  35,  46,  67,  49,  99,  63,  36,  36,  62,\n",
      "         40,  63,  31,  57,  94,  53,  16,  13,   8,  58,  28,  55,  77,  90,\n",
      "         71,  69,  50,  46,   8,  35,  82,  86,  98,  26,  21,  55,   5,  79,\n",
      "         57,  88,   4,  29,   2,  66,  70,  19,  74,  15,  87,  45,  91,  77,\n",
      "          0,  11,  34,  99,   9,  33,  43,  15,  24,  15,  89,  88,  53,  38,\n",
      "          1,  34,  97,  52,  17,   1,  41,  24,  92,  96,  85,  24,  38,   1,\n",
      "         23,  62,  97,  37,  30,  35,  44,  13,  49,  84,  91,  71,   9,  65,\n",
      "         36,  21,  79,   2,  61,  39,  26,  70,   2,  38,   6,  19,  89,  87,\n",
      "         93,  67,  70,  60,  78,   0,  71,  45]), tensor([ 57,  26,  61,   3,  94,  39,  41,  41,  82,   8,   4,  45,  17,  69,\n",
      "          2,  11,  58,  39,  93,  23,  82,  19,  92,  72,  45,  78,  25, 100,\n",
      "         26,  35,   3,  50,  27, 100,  95,   8,   1,  78,  76,  56, 100,   7,\n",
      "          1,  68,  70,  16,  33,   9,  27,  29,  30,   6,  17,   7,  74,  88,\n",
      "         14,   1,  84,  57,  92,  50,   9,  10,  57,  55,  98,  71,  95,  72,\n",
      "         20,  67,  30,  80,  33,  73,  93,  58,  90,  10,   2,  45,  39,  31,\n",
      "         13,  20,  73,  80,  97,  91,  75,  94,  85,  36,  79,  80,  39,  93,\n",
      "         76,  40,  99,  70,  29,   2,  17,   1,  53,  34,  94,  10,  15,  46,\n",
      "          0,  72,  41,  99,  60,  34,  76,  94,  27,  92,  89,  69,  28,  89,\n",
      "         82,  66,  42,  17,  54,  70,  47,  11,  95,  63,  31,  37,  31,  66,\n",
      "         17,  28,  39,  82,  20,  40,  92,  85,   8,  20,  82,  82,  97,  16,\n",
      "         60,  53,  95,  93,   7,  95,  70,  74,  64,  30,  79,  55,   9,  16,\n",
      "          8,  88,  12,  29,  24,  76,  84,  47,  45,  20,  27,  88,  62,  97,\n",
      "          7,  41,  26,  78,  48,  13,  12,  60,  41,   5,  42,  87,  16,  19,\n",
      "         38,  47,  57,  90,  53,  78,  44,  82,  47,  63,  91,   0,  83,  27,\n",
      "         95,  82,  28,   5,  43,  22,  77,  75,  31,   7,  76,  56,  36,  19,\n",
      "         32,  15,  98,  49,  89,  80,  38,  56,  52,  17,  75, 100,  24,  15,\n",
      "         14,  55,  95, 100,  86,  72,  35,  76,  95,  93,  32,  82,  95,   6,\n",
      "         53,  10,  70,  92,  36,  12,  58,  29,  57,  52,  72,  34,  73,  66,\n",
      "         44,  46,  87,  79,  55,  44,  33,  24,  72,  64,  29,  13,  78,  65,\n",
      "         62,  60,  75,  49,  81,  44,  52,  56,  60,  85,  90,  23,  21,  21,\n",
      "         60,  67,  95,  10,  52,  34,  73,  33,   3,  67,  64,  77,  25,  85,\n",
      "         86,  90,   4,   0,  97,  14,  36,  69,  81,  78,  48,  57,  53,  80,\n",
      "         63,  11,  79,  53, 100,  70,  45,  48,  25,  20,  40,  98,  62,  78,\n",
      "         25,  98,  71,  24,  78,  26,  95,  16,  42,  18,  55,  79,  41,  63,\n",
      "         57,  90,  88,  32,  96,  49,  35,  63,  80,  70,  67,  63,  64,  90,\n",
      "         73,  82,  20,  36,  41,  51,  85,   1,  66,  44,  84,  23,  12,  43,\n",
      "         16,  86,  28, 100,  97,  95,  75,  53,  71,   4,  94,  28,  98,  80,\n",
      "          4,   2,  95,   0,  41,  73,  74,  45,  93,  18,  14,  75,  43,  80,\n",
      "         84,  35,  60,  37,  68,  31,  63,  88,  64,  31,  58,  83,  93,  28,\n",
      "         64,  37,  56,  97,   0,  91,  37,   8,  17,   6,  56,  35,  99,  36,\n",
      "         30,  77,   4,  31,   9,  65,  37,   9,  91,  19,  28,  19,  43,   3,\n",
      "         33,   9,   4,  63,  32,  60,  31,  72,  89,   7,  74,   2,  73,  19,\n",
      "         89,  60,   9,  67,  50,  24,  36,  45,  62,  23,   9,  97,  95,  55,\n",
      "          4,  32,  21,  33,   5,   2,  47,  32,  97,  12,  71,  24,   7,  21,\n",
      "         40,  51,  96,  93,  56,  88,   2,  77,  31,  73,   9,   7,  39,  46,\n",
      "         55,  30,  48,  53,  87,  23,  68,  47])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "  0%|                                                                         | 0/104 [00:54<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx,(true_images, typo_images, true_labels, typo_labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(org_train_dataloader)):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(true_images), \u001b[38;5;28mlen\u001b[39m(typo_images), true_labels,\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, typo_labels)\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for idx,(true_images, typo_images, true_labels, typo_labels) in enumerate(tqdm(org_train_dataloader)):\n",
    "\n",
    "    print(len(true_images), len(typo_images), true_labels,'\\n\\n\\n\\n', typo_labels)\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "021c0dde-e739-43dd-b8ac-ca6f941d903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class ExpandedDataset(Dataset):\n",
    "    def __init__(self, dataloader):\n",
    "        self.true_images = []\n",
    "        self.typo_images = []\n",
    "        self.true_labels = []\n",
    "        self.typo_labels = []\n",
    "\n",
    "        # Expand the dataset by iterating over the dataloader\n",
    "        for _, (true_imgs, typo_imgs_list, true_lbls, typo_lbls_list) in enumerate(dataloader):\n",
    "            for i in range(len(true_imgs)):  # iterate over batch\n",
    "                for j in range(10):  # expand to 10 times by selecting one typo sample at a time\n",
    "                    self.true_images.append(true_imgs[i])\n",
    "                    self.typo_images.append(typo_imgs_list[j][i])\n",
    "                    self.true_labels.append(true_lbls[i])\n",
    "                    self.typo_labels.append(typo_lbls_list[j][i])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.true_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.true_images[idx], self.typo_images[idx], self.true_labels[idx], self.typo_labels[idx])\n",
    "\n",
    "def create_expanded_dataloader(org_dataloader):\n",
    "    batch_size = org_dataloader.batch_size\n",
    "    # Create an expanded dataset\n",
    "    expanded_dataset = ExpandedDataset(org_dataloader)\n",
    "\n",
    "    # Return a new DataLoader with the expanded dataset\n",
    "    expanded_dataloader = DataLoader(expanded_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    return expanded_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de525377-01f8-4015-a3e5-0e918566ebb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "new = create_expanded_dataloader(org_train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aac42fd4-cd43-49f4-9fbd-7fcacccd13f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512 512 tensor([  2, 100,  34,  55,  62,  98,  44,   8,  74,  67,  56,  12,  68,  54,\n",
      "          4,  35,  96,  85,   8,  74,  46,  50,  32,   7,  15,  17,  26,  42,\n",
      "         17,  69,  49,  22,  25,  24,  96,  65,  63,  99,  89,  78,   9,  47,\n",
      "         99,  16,   1,  89,  89,  32,  24,  96,  21,  36,  81,  27,  38,  77,\n",
      "          2,  80,  34,  85,  59,  33,  75,  87,  44,  72,  36,  80,  51,  54,\n",
      "          1,  89,  85,  28,  16,  26,  79,  49,   4,  36,  60,  61,  17,  48,\n",
      "         46,  66,  33,  76,  52,  76,  12,  92,  76,  17,  55,  96,  12,  29,\n",
      "         74,   0,  13,  60,  78,  28,  74,  17,  11,  61,  95,  65,  70,  73,\n",
      "         29,  39,  30,  58,  13,  10,  19,  40,  29,  60,  85,  60,  78,  27,\n",
      "         79,  44,  98,  53,  94,  25,  40,  10,  10,  52,  25,  33,  58,  78,\n",
      "          4,  52,  35,   1,  48,  85,  34,  17,  38,   2,  34,  58,  15,  29,\n",
      "          5,  38,  68,  55,  74,  57,  86,   9,  90,  12,  58,  85,  56,  99,\n",
      "          7,  94,  58,  65,  90,  51,   5,  58,  69,  89,  24,   5,  45,  14,\n",
      "         94,  25,  12,  52,  40,  28,  31,  46,   3,  98,  15,   7,  13,  29,\n",
      "         16,   4,  16,  84,  39,  60,  75,  44,  95,  84,  15,  84,  53,  47,\n",
      "         38,  98,  83,   9,  37,  19,  90,  73,  97,  92,   4,  91,  53,   3,\n",
      "        100,  22,  76,  59,  93,   1,  38,  76,   5,  74,  10,  96,  61,  76,\n",
      "         36,  59,  97,  23,  26,  19,  40,  65,  48,  77,  14,  46,  51,  96,\n",
      "         27,  37,  21,  30,  49,  97,  43,  24,   5,  13,  16,  91,   9,  46,\n",
      "         91,  64,  67,  42,  31,  77,  86,  17,  11,  23,  48,  82,  72,  90,\n",
      "         20,  48,   5,  67,  78,  66,  32,  88,  87,  12,  95,  26,  48,  79,\n",
      "         64,  66,  43,  31,  84,  55,  57,  19,  44,  31,  32,  21,   2,  19,\n",
      "         53,  73,  60,  51,  69,  87,  27,  36,  77,  44,  37,  90,  92,   8,\n",
      "         35,  19,  92,  45,   4,  68,  37,  23,  30,  92,  47,  88,  21,  13,\n",
      "         51,  92,  24, 100,  80,  33,  38,  60,  98,  64,  56,  71,  93,  76,\n",
      "         52,  45,  83,  13,  73,  84,  29,  50,  84,  35,  60,  91,  66,  28,\n",
      "         52,  45,   2,  45,  88,  90,  43,  20,  75,  89,   6,  91,  75,   1,\n",
      "         80,  38,  66,  42,  54,   2,  72,   6,  45,  24,  73,  39,  80,  53,\n",
      "         47,  23,  81,  48,  34,  69,  96,   1,  49,  83,  42,  57,  58,   5,\n",
      "         75,  93,   3,  12,  90,  83,  13,  12,  77,  37,  70,  25,  17,   4,\n",
      "         37,  36,  66,  52,  37,  84,  51,   0,  88,  80,  83,  20,  81,  55,\n",
      "         75,   2,  75,  64,  64,  89,  62,  36,  13,   5,   4,  17, 100,   3,\n",
      "         30,  78,   9,  27,  52,  32,  69,  71,  58,  39,  19,  66,  25,  72,\n",
      "         89,  11,  40,   4,  35,  14,   0,  81,  37,  54,  94,  76,  22,  94,\n",
      "          5,  12,  72,  46,  23,  87,  74,  34,  80,  92,  59,  74,  82,  27,\n",
      "         29,  84,   2,  89,  27,  52,  40,  69,  45,  37,  92,   9,  20,  59,\n",
      "         87,  14,  81,  94,  94,  39,  23,  49]) \n",
      "\n",
      "\n",
      "\n",
      " tensor([ 78,  92,  97,  62,  60,  78,   7,  51,  25,  27,  27,  23,  42,   7,\n",
      "         87,  90,  98,  11,  29,   4,  81,  70,  59,  14,  37,  73,   9,  74,\n",
      "         83,  66,  96,  73,  56,  89,  85,  51,  66,  81,  62,  86,  41,  94,\n",
      "         78,  59,  40,  44,  34,  79,  19,  67,  97,  88,  92,  95,  89,  42,\n",
      "         59,  92,  61,  10,  42,  48,  39,  72,  29,  53,  13,   9,  69,  47,\n",
      "         73,  29,  35,   0,  98,  85,  67,  18,  22,  38,  77,  27,  83,  37,\n",
      "         61,  29,  64,  91,  50,  71,  25,  50,  62,  13, 100,  76,  90,  37,\n",
      "         47,  30,  74,  47,  98,  83,  18,  92,  22,  68,   7,  35,  17,  76,\n",
      "         53,  17,  81,  27,   1,  96,  58,  71,   3,  53,  97,  46,  56,  80,\n",
      "         88,  81,  20,  90,  53,  76,  95,  35,  78,  14,  39,  81,  35,  91,\n",
      "         33,  30,  19,  75,  17,  58,  80,  86,   6,  64,  28,   3,   9,  85,\n",
      "         44,  14,  41,  37,  97,  89,  19,  98,  56,  77,  54,  27,  26,  37,\n",
      "         86,  15,  38,  84,  47,  61,  41,  42,  10,  61,  91,  94,  82,  42,\n",
      "         73,   9,  86,  66,  17,  30,  88,  38,  21,  32,  57,  54,  65,  72,\n",
      "         78,  81,  87,  26,  34,  23,  77,  46,  67,  30,   7,  87,  67,  13,\n",
      "         76,  72,  71,  59,  38,  57,  40,  79,  62,  14,  84,  85,   7,   6,\n",
      "         45,  64,  37,  82,  48,  19,  21,  79,  18,  47,  86,   0,  96, 100,\n",
      "         17,  76,  25,  90,  95,  26,  19,  10,   9,  21,   4,  82,  31,  95,\n",
      "         73,  47,  76,   2,  72,  24,  40,  85,  85,  14,  55,   3,   6,  36,\n",
      "         77,  10,  29,  34,  72,   9,   2,  90,  52,  24,   0,  66,  85,  81,\n",
      "         39,  86,  48,  22,  63,  36,  39,   2,  47,  11,  14,  91,  87,  38,\n",
      "         56,  30,  45,  42,  59,  47,  91,  68,  54,  52,  44,  41,   6,   3,\n",
      "         43,   8,  78,  35,  63,  64,  26,  91,  78,  89,  82,  79,  63, 100,\n",
      "         20,  50,  68,  67,  57,   0,  27,  48,  74,  53,  88,  41,  67,  48,\n",
      "         22,  26,  49,  31,  13,  52,   9,  15,   8,  26, 100,  20,   4,  74,\n",
      "        100,  66,   4,  76,  97,   9,  67,  41,  17,  60,  84,  66,  42,   7,\n",
      "         46,  91,  37,  62,  61,  33,  18,  10,  26,  52,  99,  45,  30,  21,\n",
      "         56,  43,  51,  78,   6,  34,  52,  30,  59,  62,  58,  78,  38,  12,\n",
      "         56,  38,  41,  78,  94,  49,  13,  88,  31,  61,  81,  71,  57,   6,\n",
      "         10,  28,  48,  87,  93,  16,  39,  49,  34,  76,   3,  90,   6,  75,\n",
      "         21,  34,  57,   7,  97,  15,  34,  91,  44,  25,  94,   6,   9,  36,\n",
      "         81,  56,  71,  16,  63,  50,   0,  21,   1,  85,  45,  80,  67,  50,\n",
      "         77,  63,  71,  17,  88,  31,  89,  14,  69,  65,  67,   3,  79,  10,\n",
      "         37,  33,  93,  62,   3,  40,  56,  55,  17,  74,  16,  61,  98,  17,\n",
      "         33,  44,  17,  83,  91,   2,  56,   4,  30,  62,  62,  87,  98,  60,\n",
      "         41,  57,  70,  82,  52,  74,  57,  28,  12,  99,  24,  10,  65,  22,\n",
      "          7,  47,  21,  83,  66,  41,  66,  77])\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx,(true_images, typo_images, true_labels, typo_labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(new):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(true_images), \u001b[38;5;28mlen\u001b[39m(typo_images), true_labels,\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, typo_labels)\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for idx,(true_images, typo_images, true_labels, typo_labels) in enumerate(new):\n",
    "\n",
    "    print(len(true_images), len(typo_images), true_labels,'\\n\\n\\n\\n', typo_labels)\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff30bd55-d9d6-4742-ba70-6eeaa037ef9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# org_train_dataloader.batch_size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
